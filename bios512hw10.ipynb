{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcbca239",
   "metadata": {},
   "source": [
    "**Question 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26c2bb27",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "also installing the dependency ‘SnowballC’\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The downloaded binary packages are in\n",
      "\t/var/folders/80/5qy32fkj60j1kv9n8rlpvtbc0000gn/T//Rtmp30hzfH/downloaded_packages\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"tokenizers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd6a9625",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"trode the hard strength that had been but small matters of my slumber and with my dear friend the master word beating in the face off from the darkness of the lesser pyramid stood in my need and it gathered itself and surely that one who says a thing in all the pyramid was sealed and so came to pass away and the ten thousand and the voice was thrilling the aether of the body to pain that i took the maid a little moment but afterward i remembered that i slumber only with a great snake from among the flowers at night treading as moon flakes step across a mighty squarking and went onward and with this ebook complying with the monstrous air shafts of the night\"\n"
     ]
    }
   ],
   "source": [
    "#a) function to tokenize text\n",
    "library(httr)\n",
    "library(tokenizers)\n",
    "\n",
    "tokenize_text <- function(text) {\n",
    "    tokenizers::tokenize_words(text, lowercase = TRUE, strip_punct = TRUE)[[1]]\n",
    "}\n",
    "\n",
    "#b) function to generate keys for ngrams\n",
    "key_from <- function(ngram, sep = \"\\x1f\") {\n",
    "    paste(ngram, collapse = sep)\n",
    "}\n",
    "\n",
    "#c) function to build ngram table\n",
    "build_ngram_table <- function(tokens, n, sep = \"\\x1f\") {\n",
    "    if (length(tokens) < n) return(new.env(parent = emptyenv()))\n",
    "\n",
    "    tbl <- new.env(parent = emptyenv())\n",
    "\n",
    "    for (i in seq_len(length(tokens) - n + 1L)) {\n",
    "        ngram <- tokens[i:(i + n - 2L)]      # context of length n-1\n",
    "        next_word <- tokens[i + n - 1L]       # the predicted word\n",
    "        key <- paste(ngram, collapse = sep)\n",
    "\n",
    "        counts <- if (!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n",
    "\n",
    "        if (next_word %in% names(counts)) {\n",
    "            counts[[next_word]] <- counts[[next_word]] + 1L\n",
    "        } else {\n",
    "            counts[[next_word]] <- 1L\n",
    "        }\n",
    "\n",
    "        tbl[[key]] <- counts\n",
    "    }\n",
    "    tbl\n",
    "}\n",
    "\n",
    "#d) function to digest the text\n",
    "digest_text <- function(text, n) {\n",
    "    tokens <- tokenize_text(text)\n",
    "    build_ngram_table(tokens, n)\n",
    "}\n",
    "\n",
    "#e) function to digest the url\n",
    "digest_url <- function(url, n) {\n",
    "    res <- httr::GET(url)\n",
    "    txt <- httr::content(res, as = \"text\", encoding = \"UTF-8\")\n",
    "    digest_text(txt, n)\n",
    "}\n",
    "\n",
    "#f) function that gives random start\n",
    "random_start <- function(tbl, sep = \"\\x1f\") {\n",
    "    keys <- ls(envir = tbl, all.names = TRUE)\n",
    "    if (length(keys) == 0) stop(\"No n-grams available. Digest text first.\")\n",
    "    picked <- sample(keys, 1)\n",
    "    strsplit(picked, sep, fixed = TRUE)[[1]]\n",
    "}\n",
    "\n",
    "#g) function to predict the next word\n",
    "predict_next_word <- function(tbl, ngram, sep = \"\\x1f\") {\n",
    "    key <- paste(ngram, collapse = sep)\n",
    "    counts <- if (!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n",
    "    if (length(counts) == 0) return(NA_character_)\n",
    "    sample(names(counts), size = 1, prob = as.numeric(counts))\n",
    "}\n",
    "\n",
    "#h) ngram generator\n",
    "make_ngram_generator <- function(tbl, n, sep = \"\\x1f\") {\n",
    "    force(tbl); n <- as.integer(n); force(sep)\n",
    "\n",
    "    function(start_words = NULL, length = 10L) {\n",
    "\n",
    "        # use random start\n",
    "        if (is.null(start_words) || length(start_words) != n - 1L) {\n",
    "            start_words <- random_start(tbl, sep = sep)\n",
    "        }\n",
    "\n",
    "        word_sequence <- start_words\n",
    "\n",
    "        for (i in seq_len(max(0L, length - length(start_words)))) {\n",
    "            ngram <- tail(word_sequence, n - 1L)\n",
    "            next_word <- predict_next_word(tbl, ngram, sep = sep)\n",
    "            if (is.na(next_word)) break\n",
    "            word_sequence <- c(word_sequence, next_word)\n",
    "        }\n",
    "\n",
    "        paste(word_sequence, collapse = \" \")\n",
    "    }\n",
    "}\n",
    "\n",
    "# example when n=3\n",
    "url <- \"https://www.gutenberg.org/cache/epub/10662/pg10662.txt\"\n",
    "tbl3 <- digest_url(url, n = 3)\n",
    "gen3 <- make_ngram_generator(tbl3, n = 3)\n",
    "\n",
    "print(gen3(length = 128))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e4c6fd",
   "metadata": {},
   "source": [
    "**Question 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e2177de",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'the king has forbidden me to marry another husband am not i shall ride upon'"
      ],
      "text/latex": [
       "'the king has forbidden me to marry another husband am not i shall ride upon'"
      ],
      "text/markdown": [
       "'the king has forbidden me to marry another husband am not i shall ride upon'"
      ],
      "text/plain": [
       "[1] \"the king has forbidden me to marry another husband am not i shall ride upon\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'spread the jam over it spread its wings and crying here comes our hobblety jib'"
      ],
      "text/latex": [
       "'spread the jam over it spread its wings and crying here comes our hobblety jib'"
      ],
      "text/markdown": [
       "'spread the jam over it spread its wings and crying here comes our hobblety jib'"
      ],
      "text/plain": [
       "[1] \"spread the jam over it spread its wings and crying here comes our hobblety jib\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'the king he added to the entire exclusion of the swords were made prisoners the'"
      ],
      "text/latex": [
       "'the king he added to the entire exclusion of the swords were made prisoners the'"
      ],
      "text/markdown": [
       "'the king he added to the entire exclusion of the swords were made prisoners the'"
      ],
      "text/plain": [
       "[1] \"the king he added to the entire exclusion of the swords were made prisoners the\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'lamentation de lemburn came forth completely armed after the fashion of this may be seen'"
      ],
      "text/latex": [
       "'lamentation de lemburn came forth completely armed after the fashion of this may be seen'"
      ],
      "text/markdown": [
       "'lamentation de lemburn came forth completely armed after the fashion of this may be seen'"
      ],
      "text/plain": [
       "[1] \"lamentation de lemburn came forth completely armed after the fashion of this may be seen\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#a)\n",
    "url_a <- \"https://www.gutenberg.org/cache/epub/2591/pg2591.txt\"\n",
    "\n",
    "tblA <- digest_url(url_a, n = 3)\n",
    "genA <- make_ngram_generator(tblA, n = 3)\n",
    "\n",
    "#a.i)\n",
    "set.seed(2025)\n",
    "genA(start_words = c(\"the\", \"king\"), length = 15)\n",
    "\n",
    "#a.ii)\n",
    "set.seed(2025)\n",
    "genA(length = 15)\n",
    "\n",
    "\n",
    "#b)\n",
    "url_b <- \"https://www.gutenberg.org/cache/epub/46342/pg46342.txt\"\n",
    "\n",
    "tblB <- digest_url(url_b, n = 3)\n",
    "genB <- make_ngram_generator(tblB, n = 3)\n",
    "\n",
    "#b.i)\n",
    "set.seed(2025)\n",
    "genB(start_words = c(\"the\", \"king\"), length = 15)\n",
    "\n",
    "#b.ii)\n",
    "set.seed(2025)\n",
    "genB(length = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499c1422",
   "metadata": {},
   "source": [
    "**Question 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa47c0fa",
   "metadata": {},
   "source": [
    "a) A language model is a type of machine learning model that predicts the probability of a sequence of words to understand and generate human language, such as Chat GPT.\n",
    "\n",
    "b) If the internet went down, a language model can be run locally by downloading an open-source model and running it on your own machine. These tools allow you to run models directly on the computer, to be used anytime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d96f23",
   "metadata": {},
   "source": [
    "**Question 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84e7565",
   "metadata": {},
   "source": [
    "| Term | Meaning |  \n",
    "|------|---------|\n",
    "| **Shell** | a program which lets you interact with all the functionality of a system (the operating system); When you type mkdir project, the shell reads those characters, parses them, and starts the mkdir process to create a directory named project |\n",
    "| **Terminal emulator** | the \"place\" the shell sits (HOSTS a shell); does not interpret mkdir project itself—it only passes your keystrokes to the shell and displays the output it returns |\n",
    "| **Process** | When you run mkdir project, the shell launches a process, the running instance of the mkdir program, that actually creates the directory; the shell itself is also a process |\n",
    "| **Signal** | things we can send to processes to tell them to do something; example would be pressing Ctrl-C to send an interrupt signal to a running process |\n",
    "| **Standard input** | the stream a process can read characters from |\n",
    "| **Standard output** | where a process writes text; if mkdir project fails, the error message you see comes through stdout or stderr |\n",
    "| **Command line argument** | in mkdir project, the word project is a command line argument: information passed to the mkdir process at startup telling it what directory to create |\n",
    "| **The environment** | the set of variables and settings visible to the mkdir process when it starts (e.g., PATH, HOME) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db02730",
   "metadata": {},
   "source": [
    "**Question 5**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a015a14f",
   "metadata": {},
   "source": [
    "a) The programs are find, xargs, and grep.\n",
    "\n",
    "b) \n",
    "'find' is being run in the current directory (.);\n",
    "'.-iname \".R\"' tells 'find' to look for files whose names end in .R, case-insensitive;\n",
    "pipe '|' takes the output of 'find' and sends it as standard input to 'xargs';\n",
    "'xargs' feeds the list of found files as command-line arguments to 'grep';\n",
    "'grep' searches each of the provided files for the text 'read_csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75a5aab",
   "metadata": {},
   "source": [
    "**Question 6**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8283e72",
   "metadata": {},
   "source": [
    "a) Unable to find image 'hello-world:latest' locally\n",
    "latest: Pulling from library/hello-world\n",
    "d080f19a4b5c: Pull complete\n",
    "Digest: sha256:9c07d0ea8…(long hash)…  \n",
    "Status: Downloaded newer image for hello-world:latest\n",
    "\n",
    "Hello from Docker!\n",
    "This message shows that your installation appears to be working correctly.\n",
    "\n",
    "To generate this message, Docker took the following steps:\n",
    " 1. The Docker client contacted the Docker daemon.\n",
    " 2. The Docker daemon pulled the \"hello-world\" image from Docker Hub.\n",
    "    (amd64)\n",
    " 3. The Docker daemon created a new container from that image.\n",
    " 4. The Docker daemon streamed the output to your terminal.\n",
    "\n",
    "To try something more ambitious, you can run an Ubuntu container with:\n",
    "  $ docker run -it ubuntu bash\n",
    "\n",
    "Share images, automate workflows, and more with a free Docker ID:\n",
    "  https://hub.docker.com/\n",
    "\n",
    "b) [INFO] RStudio Server is running at http://0.0.0.0:8787/\n",
    "[INFO] User: rstudio Password: <your_password>\n",
    "[INFO] Mounted directory: /home/rstudio\n",
    "\n",
    "c) http://localhost:8787 \n",
    "use rstudio as the user and the password you set as the password"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
